{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f59585cd",
   "metadata": {},
   "source": [
    "# Experiment Design - Simulating the A/B Test\n",
    "\n",
    "**Ridham Patel | January 2026**\n",
    "\n",
    "## What I'm Doing\n",
    "\n",
    "Now that I have user segments from my EDA, I need to design and simulate an A/B test to see if my Vibe Shift feature actually works.\n",
    "\n",
    "The plan:\n",
    "- Randomly assign users to Control (normal recs) vs Treatment (opposite recs)\n",
    "- Make sure each segment is balanced across both groups (stratified randomization from my ML course)\n",
    "- Simulate what would happen to engagement\n",
    "- Check for unintended consequences (guardrail metrics)\n",
    "\n",
    "**Important note:** This is a simulated experiment for my portfolio. In production, we'd run this on real users and measure actual behavior. But for now I'm creating realistic synthetic data to demonstrate the experimental design process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4f209",
   "metadata": {},
   "source": [
    "# Import and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9bdb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e1be12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"playlist_comfort_zones.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "401ef168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>comfort_zone_score</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0275i1VNfBnsNbPl0QIBpG</td>\n",
       "      <td>0.204712</td>\n",
       "      <td>0.136614</td>\n",
       "      <td>0.170663</td>\n",
       "      <td>Moderate Comfort Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03qQtbNHoJuFezRu2CnLuF</td>\n",
       "      <td>0.235168</td>\n",
       "      <td>0.197765</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>Wide Comfort Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03sDEv7FN58Mb9CJOs1Tgn</td>\n",
       "      <td>0.192502</td>\n",
       "      <td>0.109796</td>\n",
       "      <td>0.151149</td>\n",
       "      <td>Moderate Comfort Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06zrBJ5cts5aemZmqe80J7</td>\n",
       "      <td>0.188636</td>\n",
       "      <td>0.120561</td>\n",
       "      <td>0.154599</td>\n",
       "      <td>Moderate Comfort Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07SNJ4MwYba9wwmzrbjmYi</td>\n",
       "      <td>0.203764</td>\n",
       "      <td>0.133636</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>Moderate Comfort Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              playlist_id   valence    energy  comfort_zone_score  \\\n",
       "0  0275i1VNfBnsNbPl0QIBpG  0.204712  0.136614            0.170663   \n",
       "1  03qQtbNHoJuFezRu2CnLuF  0.235168  0.197765            0.216467   \n",
       "2  03sDEv7FN58Mb9CJOs1Tgn  0.192502  0.109796            0.151149   \n",
       "3  06zrBJ5cts5aemZmqe80J7  0.188636  0.120561            0.154599   \n",
       "4  07SNJ4MwYba9wwmzrbjmYi  0.203764  0.133636            0.168700   \n",
       "\n",
       "                 segment  \n",
       "0  Moderate Comfort Zone  \n",
       "1      Wide Comfort Zone  \n",
       "2  Moderate Comfort Zone  \n",
       "3  Moderate Comfort Zone  \n",
       "4  Moderate Comfort Zone  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728147b",
   "metadata": {},
   "source": [
    "# Stratified Random Assignment\n",
    "\n",
    "This is important in order to have a balanced representation of each segment is present in both treatment and control groups.\n",
    "\n",
    "### Methodology:\n",
    "- Stratification variable: Segment (Narrow/Moderate/Wide)\n",
    "- Assignment ratio: 50/50 (Control/Treatment)\n",
    "- Randomization: Permutation during assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1990d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "# 42\n",
    "np.random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d908353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Segment Distribution\n",
      "segment\n",
      "Moderate Comfort Zone    272\n",
      "Narrow Comfort Zone      120\n",
      "Wide Comfort Zone         78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total playlists: 470\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Segment Distribution\")\n",
    "segment_counts = df['segment'].value_counts().sort_index()\n",
    "print(segment_counts)\n",
    "print(f\"\\nTotal playlists: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd8cf088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_experiment_group(segment_df):\n",
    "    n = len(segment_df)\n",
    "    indices = segment_df.index.tolist()\n",
    "\n",
    "    shuffled_indices = np.random.permutation(indices)\n",
    "\n",
    "    split_point =  n // 2\n",
    "    control_indices = shuffled_indices[:split_point]\n",
    "    treatment_indices = shuffled_indices[split_point:]\n",
    "\n",
    "    assigment = pd.Series(index=indices)\n",
    "\n",
    "    assigment.loc[control_indices] = 'Control'\n",
    "    assigment.loc[treatment_indices] = 'Treatment'\n",
    "\n",
    "    return assigment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfb0a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/6zbxrfhs3673cn004nn1v62h0000gn/T/ipykernel_47987/3004289535.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Control' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  assigment.loc[control_indices] = 'Control'\n",
      "/var/folders/w6/6zbxrfhs3673cn004nn1v62h0000gn/T/ipykernel_47987/3004289535.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Control' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  assigment.loc[control_indices] = 'Control'\n",
      "/var/folders/w6/6zbxrfhs3673cn004nn1v62h0000gn/T/ipykernel_47987/3004289535.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Control' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  assigment.loc[control_indices] = 'Control'\n"
     ]
    }
   ],
   "source": [
    "#Performing stratified random assignment\n",
    "\n",
    "for segment in df['segment'].unique():\n",
    "    seg_mask = df['segment'] == segment\n",
    "    segment_df = df[seg_mask]\n",
    "    assignments = assign_experiment_group(segment_df)\n",
    "    df.loc[seg_mask, 'experiment_group'] = assignments\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54110eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosstab\n",
      "\n",
      " experiment_group       Control  Treatment  Total\n",
      "segment                                         \n",
      "Moderate Comfort Zone      136        136    272\n",
      "Narrow Comfort Zone         60         60    120\n",
      "Wide Comfort Zone           39         39     78\n",
      "Total                      235        235    470\n",
      "\n",
      "Percentage Split within each segment\n",
      "\n",
      " experiment_group       Control  Treatment\n",
      "segment                                  \n",
      "Moderate Comfort Zone     50.0       50.0\n",
      "Narrow Comfort Zone       50.0       50.0\n",
      "Wide Comfort Zone         50.0       50.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Crosstab\")\n",
    "\n",
    "crosstab = pd.crosstab(df['segment'], df['experiment_group'], margins=True,margins_name='Total')\n",
    "print(\"\\n\", crosstab)\n",
    "\n",
    "print(\"\\nPercentage Split within each segment\")\n",
    "\n",
    "crosstab_pct = pd.crosstab(df['segment'], df['experiment_group'], normalize='index') * 100\n",
    "print(\"\\n\", crosstab_pct.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ff5a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification: Total Counts\n",
      "\n",
      "Split: 50.0% Control, 50.000% Treatment\n",
      "\n",
      "All playlists successfully assigned!\n"
     ]
    }
   ],
   "source": [
    "print(\"Verification: Total Counts\")\n",
    "\n",
    "total_control = (df['experiment_group'] == 'Control').sum()\n",
    "total_treatment = (df['experiment_group'] == 'Treatment').sum()\n",
    "\n",
    "print(f\"\\nSplit: {total_control/len(df)*100:.1f}% Control, {total_treatment/len(df)*100:.3f}% Treatment\")\n",
    "\n",
    "# Check for any missing assignments\n",
    "if df['experiment_group'].isna().any():\n",
    "    print(\"\\nWARNING: Some playlists were not assigned!\")\n",
    "    print(f\"Missing: {df['experiment_group'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"\\nAll playlists successfully assigned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300acdab",
   "metadata": {},
   "source": [
    "- Perfect balanced achieved across all segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a886f7c1",
   "metadata": {},
   "source": [
    "### Sanity Check - Are the Groups Balanced?\n",
    "\n",
    "Before running the experiment, I need to verify that randomization worked properly. Let me check if Control and Treatment groups are similar on key variables:\n",
    "\n",
    "**Comfort zone score** - This is what I used for segmentation, so it should be balanced. If Treatment has more stuck users on average, that would bias the results.\n",
    "\n",
    "**Song count** - Bigger playlists = more opportunity to engage. Need to make sure one group doesn't have systematically larger playlists.\n",
    "\n",
    "If these are balanced, any differences in outcomes are due to the treatment, not pre-existing differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b98ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"spotify.csv\")\n",
    "\n",
    "df3 = df.merge(df2, on = \"playlist_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2613f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count songs per playlist\n",
    "song_counts = df3.groupby('playlist_id').size().reset_index(name='song_count')\n",
    "\n",
    "df4 = df3.merge(song_counts, on = \"playlist_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6391931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for Balance\n",
      "\n",
      " Average Comfort Zone Score:\n",
      "                    mean     std  count\n",
      "experiment_group                       \n",
      "Control           0.1695  0.0278    235\n",
      "Treatment         0.1661  0.0277    235\n",
      "Difference: 0.0034 GOOD\n",
      "\n",
      " Average Song Count:\n",
      "                  mean   std  count\n",
      "experiment_group                   \n",
      "Control           82.8  28.2  16205\n",
      "Treatment         84.4  33.3  16627\n",
      "Difference: 1.6 GOOD\n"
     ]
    }
   ],
   "source": [
    "print(\"Check for Balance\")\n",
    "\n",
    "\n",
    "print(\"\\n Average Comfort Zone Score:\")\n",
    "balance_check = df.groupby('experiment_group')['comfort_zone_score'].agg(['mean', 'std', 'count'])\n",
    "print(balance_check.round(4))\n",
    "\n",
    "difference = abs(balance_check.loc['Control', 'mean'] - balance_check.loc['Treatment', 'mean'])\n",
    "print(f\"Difference: {difference:.4f} {'GOOD' if difference < 0.005 else 'CHECK'}\")\n",
    "\n",
    "print(\"\\n Average Song Count:\")\n",
    "balance_check_songs = df4.groupby('experiment_group')['song_count'].agg(['mean', 'std', 'count'])\n",
    "print(balance_check_songs.round(1))\n",
    "\n",
    "difference_songs = abs(balance_check_songs.loc['Control', 'mean'] - balance_check_songs.loc['Treatment', 'mean'])\n",
    "print(f\"Difference: {difference_songs:.1f} {'GOOD' if difference_songs < 2 else 'CHECK'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac79f1",
   "metadata": {},
   "source": [
    "\n",
    "- Groups are perfectly balanced this means that any outcome differences are due to treatment, not baseline differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad97e2f9",
   "metadata": {},
   "source": [
    "## Simulating Baseline Engagement\n",
    "\n",
    "Since this is a portfolio project, I don't have real user data. I need to simulate realistic engagement levels for each segment.\n",
    "\n",
    "**My assumption:** users with wider comfort zones probably already engage more. Users with narrow zones engage less.\n",
    "\n",
    "**Baseline engagement I'm simulating (songs liked per session):**\n",
    "- Narrow users: 5 songs ± 1.2 (they're stuck, don't explore much)\n",
    "- Moderate users: 7 songs ± 1.5 (balanced)\n",
    "- Wide users: 9 songs ± 1.8 (already high engagement)\n",
    "\n",
    "I based these numbers on what seems realistic for music streaming.\n",
    "\n",
    "**Important:** These are made-up numbers for simulation purposes. In a real A/B test, I'd measure actual baseline engagement before the experiment starts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44c99171",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "def simulate_baseline_engagement(row):\n",
    "    segment = row['segment']\n",
    "    \n",
    "    if segment == 'Narrow Comfort Zone':\n",
    "        mean, std = 5.0, 1.2\n",
    "    elif segment == 'Moderate Comfort Zone':\n",
    "        mean, std = 7.0, 1.5\n",
    "    else:  \n",
    "        mean, std = 9.0, 1.8\n",
    "    \n",
    "    baseline = np.random.normal(mean, std)\n",
    "    return max(0.5, baseline) \n",
    "\n",
    "df['baseline_engagement'] = df.apply(simulate_baseline_engagement, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d769d35",
   "metadata": {},
   "source": [
    "# Calculate Average Playlist Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c509a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs = pd.read_csv(\"spotify.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1490d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_averages = df_songs.groupby('playlist_id').agg({'valence': 'mean', 'energy': 'mean'}).round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9379ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_averages.columns = ['avg_valence', 'avg_energy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d4dd2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Statistics:\n",
      "Valence - Mean: 0.517, Std: 0.126, Range: [0.045, 0.844]\n",
      "Energy  - Mean: 0.701, Std: 0.110, Range: [0.243, 0.931]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOverall Statistics:\")\n",
    "print(f\"Valence - Mean: {playlist_averages['avg_valence'].mean():.3f}, \"\n",
    "      f\"Std: {playlist_averages['avg_valence'].std():.3f}, \"\n",
    "      f\"Range: [{playlist_averages['avg_valence'].min():.3f}, {playlist_averages['avg_valence'].max():.3f}]\")\n",
    "print(f\"Energy  - Mean: {playlist_averages['avg_energy'].mean():.3f}, \"\n",
    "      f\"Std: {playlist_averages['avg_energy'].std():.3f}, \"\n",
    "      f\"Range: [{playlist_averages['avg_energy'].min():.3f}, {playlist_averages['avg_energy'].max():.3f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fc61f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'playlist_id' not in df.columns:\n",
    "    df = df.reset_index()\n",
    "\n",
    "df = df.merge(playlist_averages, left_on='playlist_id', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f79e22d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>comfort_zone_score</th>\n",
       "      <th>segment</th>\n",
       "      <th>experiment_group</th>\n",
       "      <th>baseline_engagement</th>\n",
       "      <th>avg_valence</th>\n",
       "      <th>avg_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0275i1VNfBnsNbPl0QIBpG</td>\n",
       "      <td>0.204712</td>\n",
       "      <td>0.136614</td>\n",
       "      <td>0.170663</td>\n",
       "      <td>Moderate Comfort Zone</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>7.745071</td>\n",
       "      <td>0.5560</td>\n",
       "      <td>0.7150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03qQtbNHoJuFezRu2CnLuF</td>\n",
       "      <td>0.235168</td>\n",
       "      <td>0.197765</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>Wide Comfort Zone</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>8.751124</td>\n",
       "      <td>0.5961</td>\n",
       "      <td>0.7341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03sDEv7FN58Mb9CJOs1Tgn</td>\n",
       "      <td>0.192502</td>\n",
       "      <td>0.109796</td>\n",
       "      <td>0.151149</td>\n",
       "      <td>Moderate Comfort Zone</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>7.971533</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.7013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06zrBJ5cts5aemZmqe80J7</td>\n",
       "      <td>0.188636</td>\n",
       "      <td>0.120561</td>\n",
       "      <td>0.154599</td>\n",
       "      <td>Moderate Comfort Zone</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>9.284545</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.6862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07SNJ4MwYba9wwmzrbjmYi</td>\n",
       "      <td>0.203764</td>\n",
       "      <td>0.133636</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>Moderate Comfort Zone</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>6.648770</td>\n",
       "      <td>0.4984</td>\n",
       "      <td>0.5044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              playlist_id   valence    energy  comfort_zone_score  \\\n",
       "0  0275i1VNfBnsNbPl0QIBpG  0.204712  0.136614            0.170663   \n",
       "1  03qQtbNHoJuFezRu2CnLuF  0.235168  0.197765            0.216467   \n",
       "2  03sDEv7FN58Mb9CJOs1Tgn  0.192502  0.109796            0.151149   \n",
       "3  06zrBJ5cts5aemZmqe80J7  0.188636  0.120561            0.154599   \n",
       "4  07SNJ4MwYba9wwmzrbjmYi  0.203764  0.133636            0.168700   \n",
       "\n",
       "                 segment experiment_group  baseline_engagement  avg_valence  \\\n",
       "0  Moderate Comfort Zone        Treatment             7.745071       0.5560   \n",
       "1      Wide Comfort Zone        Treatment             8.751124       0.5961   \n",
       "2  Moderate Comfort Zone        Treatment             7.971533       0.6616   \n",
       "3  Moderate Comfort Zone        Treatment             9.284545       0.5303   \n",
       "4  Moderate Comfort Zone        Treatment             6.648770       0.4984   \n",
       "\n",
       "   avg_energy  \n",
       "0      0.7150  \n",
       "1      0.7341  \n",
       "2      0.7013  \n",
       "3      0.6862  \n",
       "4      0.5044  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d41e4b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values - all playlists have averages\n"
     ]
    }
   ],
   "source": [
    "missing_valence = df['avg_valence'].isna().sum()\n",
    "missing_energy = df['avg_energy'].isna().sum()\n",
    "\n",
    "if missing_valence > 0 or missing_energy > 0:\n",
    "    print(f\"Missing values after merge:\")\n",
    "    print(f\"avg_valence: {missing_valence}\")\n",
    "    print(f\"vg_energy: {missing_energy}\")\n",
    "else:\n",
    "    print(\"No missing values - all playlists have averages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83378504",
   "metadata": {},
   "source": [
    "## 3. Define Treatment: Opposite Recommendations\n",
    "\n",
    "This is the logic that I used:\n",
    "\n",
    "**Control Group:**\n",
    "- Receives recommendations similar to current listening\n",
    "- `target_valence = current_valence`\n",
    "- `target_energy = current_energy`\n",
    "\n",
    "**Treatment Group:**\n",
    "- Receives **opposite** recommendations\n",
    "- `target_valence = 1 - current_valence`\n",
    "- `target_energy = 1 - current_energy`\n",
    "\n",
    "This creates a shift in the valence-energy space, pushing users outside their comfort zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "327f12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_targets(row):\n",
    "    if row['experiment_group'] == 'Control':\n",
    "        target_valence = row['avg_valence']\n",
    "        target_energy = row['avg_energy']\n",
    "    else:  \n",
    "        target_valence = 1 - row['avg_valence']\n",
    "        target_energy = 1 - row['avg_energy']\n",
    "\n",
    "    return pd.Series({'target_valence': round(target_valence, 4),\n",
    "        'target_energy': round(target_energy, 4) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96e982e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['target_valence', 'target_energy']] = df.apply(calculate_targets, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6339c9fd",
   "metadata": {},
   "source": [
    "### Shift Distance Analysis\n",
    "\n",
    "- Here, I am calculating Euclidean distance in valence-energy space\n",
    "\n",
    "- This is for the treatment group only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "261379f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Shift Distance by Segment:\n",
      "                      valence_shift        energy_shift        total_shift       \n",
      "                               mean    std         mean    std        mean    std\n",
      "segment                                                                          \n",
      "Moderate Comfort Zone         0.174  0.129        0.379  0.176       0.435  0.181\n",
      "Narrow Comfort Zone           0.278  0.172        0.566  0.168       0.651  0.178\n",
      "Wide Comfort Zone             0.165  0.109        0.318  0.169       0.378  0.160\n"
     ]
    }
   ],
   "source": [
    "\n",
    "treatment_df = df[df['experiment_group'] == 'Treatment'].copy()\n",
    "\n",
    "treatment_df['valence_shift'] = abs(treatment_df['target_valence'] - treatment_df['avg_valence'])\n",
    "treatment_df['energy_shift'] = abs(treatment_df['target_energy'] - treatment_df['avg_energy'])\n",
    "treatment_df['total_shift'] = np.sqrt(treatment_df['valence_shift']**2 + treatment_df['energy_shift']**2)\n",
    "\n",
    "shift_by_segment = treatment_df.groupby('segment')[['valence_shift', 'energy_shift', 'total_shift']].agg(['mean', 'std']).round(3)\n",
    "\n",
    "print(\"\\nAverage Shift Distance by Segment:\")\n",
    "print(shift_by_segment.to_string())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29181f3e",
   "metadata": {},
   "source": [
    "### What this means:\n",
    "\n",
    "Looking at the results, Narrow users have the largest shifts (0.651 average distance in the valence-energy space). This makes sense - they're clustered tightly in one area, so opposite recommendations are far away.\n",
    "\n",
    "Wide users have smaller shifts (0.378) because they're already spread out. Their opposite isn't that far from what they already listen to.\n",
    "\n",
    "This confirms my hypothesis about who will be most affected by the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59843b",
   "metadata": {},
   "source": [
    "## Simulating Treatment Effects\n",
    "\n",
    "Here's where I simulate what happens when users get opposite recommendations.\n",
    "\n",
    "**My hypothesis:** the effect depends on how stuck users are in their comfort zones:\n",
    "- **Narrow users** (most stuck) → biggest boost (+18% engagement)\n",
    "- **Moderate users** (balanced) → medium boost (+10% engagement)  \n",
    "- **Wide users** (already exploring) → small boost (+2% engagement)\n",
    "\n",
    "I'm adding some randomness (±4-6% std deviation) because real effects always vary across users.\n",
    "\n",
    "**The simulation math:**\n",
    "- **Control group:** engagement = baseline + random noise (no change)\n",
    "- **Treatment group:** engagement = baseline × (1 + lift%) + random noise\n",
    "\n",
    "**Important reminder:** These effect sizes are made up for demonstration. In reality, you'd measure actual user behavior after launch and might see very different results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5810c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_treatment_effect(row):\n",
    "    baseline = row['baseline_engagement']\n",
    "    segment = row['segment']\n",
    "    group = row['experiment_group']\n",
    "    \n",
    "    if group == 'Control':\n",
    "        post = baseline + np.random.normal(0, 0.5)\n",
    "        return max(0.5, post)\n",
    "    \n",
    "    if segment == 'Narrow Comfort Zone':\n",
    "        expected_lift = 0.18  \n",
    "        std_lift = 0.05\n",
    "    elif segment == 'Moderate Comfort Zone':\n",
    "        expected_lift = 0.10  \n",
    "        std_lift = 0.04\n",
    "    else:  \n",
    "        expected_lift = 0.02  \n",
    "        std_lift = 0.06\n",
    "    \n",
    "    lift = np.random.normal(expected_lift, std_lift)\n",
    "    \n",
    "    post = baseline * (1 + lift) + np.random.normal(0, 0.5)\n",
    "    return max(0.5, post)\n",
    "\n",
    "df['post_treatment_engagement'] = df.apply(simulate_treatment_effect, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c5404cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual Average Lifts by Segment:\n",
      "                       mean   std\n",
      "segment                          \n",
      "Moderate Comfort Zone  10.4   8.4\n",
      "Narrow Comfort Zone    20.1  12.7\n",
      "Wide Comfort Zone       4.6   7.8\n"
     ]
    }
   ],
   "source": [
    "# Actual lifts achieved\n",
    "print(\"\\nActual Average Lifts by Segment:\")\n",
    "treatment_df = df[df['experiment_group'] == 'Treatment'].copy()\n",
    "treatment_df['actual_lift_pct'] = ((treatment_df['post_treatment_engagement'] - treatment_df['baseline_engagement']) / treatment_df['baseline_engagement'] * 100)\n",
    "\n",
    "lift_summary = treatment_df.groupby('segment')['actual_lift_pct'].agg(['mean', 'std']).round(1)\n",
    "print(lift_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e22ecae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Control Group (should be ~0% lift):\n",
      "Average lift: -0.02% (expected: ~0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nControl Group (should be ~0% lift):\")\n",
    "control_df = df[df['experiment_group'] == 'Control'].copy()\n",
    "control_df['actual_lift_pct'] = ((control_df['post_treatment_engagement'] - control_df['baseline_engagement']) / control_df['baseline_engagement'] * 100)\n",
    "control_lift = control_df['actual_lift_pct'].mean()\n",
    "print(f\"Average lift: {control_lift:.2f}% (expected: ~0%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb74d411",
   "metadata": {},
   "source": [
    "## Defining My Metrics\n",
    "\n",
    "### Primary Metric: Songs Liked per Session\n",
    "\n",
    "This is my main success metric - did opposite recs increase engagement?\n",
    "\n",
    "I'm measuring how many songs users like (heart/save) during a session. This is a good metric because:\n",
    "- It's direct engagement \n",
    "- We can actually improve it through better recommendations\n",
    "\n",
    "**My hypothesis:** Opposite recommendations push users to discover new music they actually like, so they'll save more songs per session.\n",
    "\n",
    "\n",
    "### Secondary Metric: Discovery Diversity  \n",
    "\n",
    "I also want to check if the feature works HOW I think it works. Does it actually increase musical exploration?\n",
    "\n",
    "I'll measure variance in the music characteristics users engage with (std dev across valence/energy). If the treatment works, users should explore a wider range of moods and energy levels.\n",
    "\n",
    "This validates the mechanism behind the feature.\n",
    "\n",
    "\n",
    "### Guardrail Metrics \n",
    "\n",
    "Increasing engagement is great, but what if users hate the experience? A feature could technically work but frustrate users.\n",
    "\n",
    "Two things I'm monitoring to catch problems early:\n",
    "\n",
    "**1. Session Length** - Are users quitting early because they're annoyed?\n",
    "- **Threshold:** Can't drop by more than 5%\n",
    "- If users leave early, that's a red flag even if engagement goes up\n",
    "\n",
    "**2. Skip Rate** - Are users skipping tons of songs to find something they like?\n",
    "- **Threshold:** Can't increase by more than 10 percentage points  \n",
    "- Some skipping is ok as they are exploring, but too much means bad recommendations\n",
    "\n",
    "**Why this matters:** The primary metric can improve but actually hurt the user experience. Guardrails prevent launching something that technically works but users hate.\n",
    "\n",
    "\n",
    "### Adding baseline metrics\n",
    "\n",
    "This is the logic that I used - \n",
    "\n",
    "- Narrow users have low diversity\n",
    "- Wide users have HIGH diversity\n",
    "\n",
    "#### Guardrail 1: Session length (minutes)\n",
    "- Everyone has similar session length (~35 min)\n",
    "\n",
    "#### Guardrail 2: Skip rate (proportion of songs skipped)\n",
    "- Everyone has similar skip rate (~35%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b340039",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assign_baseline_diversity(segment):\n",
    "    if segment == 'Narrow Comfort Zone':\n",
    "        return np.random.normal(0.15, 0.02)  \n",
    "    elif segment == 'Moderate Comfort Zone':\n",
    "        return np.random.normal(0.20, 0.02)  \n",
    "    else:  \n",
    "        return np.random.normal(0.25, 0.03) \n",
    "\n",
    "df['baseline_diversity'] = df['segment'].apply(assign_baseline_diversity)\n",
    "\n",
    "\n",
    "df['baseline_session_length'] = np.random.normal(35, 5, len(df))\n",
    "\n",
    "df['baseline_skip_rate'] = np.random.normal(0.35, 0.05, len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b843675",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "\n",
    "### Simulation Logic:\n",
    "\n",
    "#### **Control Group:**\n",
    "No treatment effect - small random noise only\n",
    "- Diversity: baseline + noise\n",
    "- Session length: baseline + noise  \n",
    "- Skip rate: baseline + noise\n",
    "\n",
    "#### **Treatment Group (Segment-Specific Effects):**\n",
    "\n",
    "**Narrow Comfort Zone:**\n",
    "- Diversity: **+15%** (large discovery boost - exploring totally new genres)\n",
    "- Session length: **+2%** (slight increase - curious to explore)\n",
    "- Skip rate: **+12pp** (major increase - Opposite recommendations feel too jarring)\n",
    "\n",
    "**Reason:** Users stuck in high-energy music get low-energy recommendations. They skip several songs before finding something they like. Eventually engagement improves, but initial friction is high.\n",
    "\n",
    "**Moderate Comfort Zone:**\n",
    "- Diversity: **+8%** (medium discovery boost)\n",
    "- Session length: **+1%** (minimal change)\n",
    "- Skip rate: **+3pp** (small, acceptable increase)\n",
    "\n",
    "**Reason:** Some disruption but manageable. Users are already somewhat diverse, so opposite recs are less shocking.\n",
    "\n",
    "**Wide Comfort Zone:**\n",
    "- Diversity: **+2%** (minimal - already diverse)\n",
    "- Session length: **0%** (no change)\n",
    "- Skip rate: **+1pp** (negligible)\n",
    "\n",
    "**Reason:** Already exploring diverse music. Opposite recs don't add much value.\n",
    "\n",
    "### Note:\n",
    "\n",
    "The **+12pp skip rate for Narrow** creates a **guardrail violation** (exceeds 10pp threshold). This is intentional in the simulation to handle guardrail violations.\n",
    "\n",
    "### Constraints Applied:\n",
    "\n",
    "- **Diversity:** Minimum 0.05 (can't be negative)\n",
    "- **Session length:** Minimum 10 minutes (realistic lower bound)\n",
    "- **Skip rate:** Clipped to [0.1, 0.8] range (10-80%, realistic bounds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca725c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_secondary_guardrails(row):\n",
    "    \n",
    "    if row['experiment_group'] == 'Control':\n",
    "        diversity = row['baseline_diversity'] + np.random.normal(0, 0.01)\n",
    "        session = row['baseline_session_length'] + np.random.normal(0, 1)\n",
    "        skip = row['baseline_skip_rate'] + np.random.normal(0, 0.02)\n",
    "        \n",
    "    else:  \n",
    "        segment = row['segment']\n",
    "        \n",
    "        if segment == 'Narrow Comfort Zone':\n",
    "            diversity = row['baseline_diversity'] * 1.15 + np.random.normal(0, 0.01)\n",
    "            session = row['baseline_session_length'] * 1.02 + np.random.normal(0, 1)\n",
    "            \n",
    "            skip = row['baseline_skip_rate'] + 0.12 + np.random.normal(0, 0.02)\n",
    "            \n",
    "        elif segment == 'Moderate Comfort Zone':\n",
    "            diversity = row['baseline_diversity'] * 1.08 + np.random.normal(0, 0.01)\n",
    "            session = row['baseline_session_length'] * 1.01 + np.random.normal(0, 1)\n",
    "            skip = row['baseline_skip_rate'] + 0.03 + np.random.normal(0, 0.02)\n",
    "            \n",
    "        else:  \n",
    "            diversity = row['baseline_diversity'] * 1.02 + np.random.normal(0, 0.01)\n",
    "            session = row['baseline_session_length'] * 1.00 + np.random.normal(0, 1)\n",
    "            skip = row['baseline_skip_rate'] + 0.01 + np.random.normal(0, 0.02)\n",
    "    \n",
    "    return pd.Series({'post_diversity': max(0.05, diversity), 'post_session_length': max(10, session), 'post_skip_rate': np.clip(skip, 0.1, 0.8)})\n",
    "\n",
    "df[['post_diversity', 'post_session_length', 'post_skip_rate']] = df.apply(simulate_secondary_guardrails, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36371ed",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "020501f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Metric - Engagement\n",
      "\n",
      "Treatment Group - Engagement Lift by Segment:\n",
      "                       mean   std\n",
      "segment                          \n",
      "Moderate Comfort Zone  10.4   8.4\n",
      "Narrow Comfort Zone    20.1  12.7\n",
      "Wide Comfort Zone       4.6   7.8\n",
      "\n",
      "Control Group - Engagement Lift: -0.02% (expected: ~0%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Primary Metric - Engagement\")\n",
    "treatment_df = df[df['experiment_group'] == 'Treatment'].copy()\n",
    "treatment_df['engagement_lift_pct'] = ((treatment_df['post_treatment_engagement'] - treatment_df['baseline_engagement']) / treatment_df['baseline_engagement'] * 100)\n",
    "engagement_summary = treatment_df.groupby('segment')['engagement_lift_pct'].agg(['mean', 'std']).round(1)\n",
    "print(\"\\nTreatment Group - Engagement Lift by Segment:\")\n",
    "print(engagement_summary)\n",
    "\n",
    "# Control group\n",
    "control_df = df[df['experiment_group'] == 'Control'].copy()\n",
    "control_engagement_lift = ((control_df['post_treatment_engagement'] - control_df['baseline_engagement']) / control_df['baseline_engagement'] * 100).mean()\n",
    "print(f\"\\nControl Group - Engagement Lift: {control_engagement_lift:.2f}% (expected: ~0%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30e83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Secondary Metric - Discovery Diversity\n",
      "\n",
      "Treatment Group - Diversity Lift by Segment:\n",
      "                       mean  std\n",
      "segment                         \n",
      "Moderate Comfort Zone   8.5  4.4\n",
      "Narrow Comfort Zone    14.1  6.5\n",
      "Wide Comfort Zone       2.2  4.6\n",
      "\n",
      "Control Group - Diversity Lift: 0.17% (expected: ~0%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nSecondary Metric - Discovery Diversity\")\n",
    "# Treatment group\n",
    "treatment_df['diversity_lift_pct'] = ((treatment_df['post_diversity'] - treatment_df['baseline_diversity']) / treatment_df['baseline_diversity'] * 100)\n",
    "diversity_summary = treatment_df.groupby('segment')['diversity_lift_pct'].agg(['mean', 'std']).round(1)\n",
    "print(\"\\nTreatment Group - Diversity Lift by Segment:\")\n",
    "print(diversity_summary)\n",
    "\n",
    "# Control group\n",
    "control_diversity_lift = ((control_df['post_diversity'] - control_df['baseline_diversity']) / control_df['baseline_diversity'] * 100).mean()\n",
    "print(f\"\\nControl Group - Diversity Lift: {control_diversity_lift:.2f}% (expected: ~0%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84513ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Guardrail Metric 1 - Session Length\n",
      "\n",
      "Treatment Group - Session Length Change by Segment:\n",
      "                       mean  std\n",
      "segment                         \n",
      "Moderate Comfort Zone   0.5  3.3\n",
      "Narrow Comfort Zone     2.5  3.0\n",
      "Wide Comfort Zone       0.0  2.9\n",
      "\n",
      "Control Group - Session Length Change: -0.44% (expected: ~0%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nGuardrail Metric 1 - Session Length\")\n",
    "# Treatment group\n",
    "treatment_df['session_lift_pct'] = ((treatment_df['post_session_length'] - treatment_df['baseline_session_length']) / treatment_df['baseline_session_length'] * 100)\n",
    "session_summary = treatment_df.groupby('segment')['session_lift_pct'].agg(['mean', 'std']).round(1)\n",
    "print(\"\\nTreatment Group - Session Length Change by Segment:\")\n",
    "print(session_summary)\n",
    "\n",
    "# Control group\n",
    "control_session_lift = ((control_df['post_session_length'] - control_df['baseline_session_length']) / control_df['baseline_session_length'] * 100).mean()\n",
    "print(f\"\\nControl Group - Session Length Change: {control_session_lift:.2f}% (expected: ~0%)\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340cb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Guardrail Metric 2 - Skip Rate\n",
      "\n",
      "Treatment Group - Skip Rate Change (pp) by Segment:\n",
      "                       mean  std\n",
      "segment                         \n",
      "Moderate Comfort Zone   3.0  1.9\n",
      "Narrow Comfort Zone    11.6  1.8\n",
      "Wide Comfort Zone       1.5  1.6\n",
      "\n",
      "Control Group - Skip Rate Change: -0.17pp (expected: ~0pp)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nGuardrail Metric 2 - Skip Rate\")\n",
    "\n",
    "# Treatment group\n",
    "treatment_df['skip_change_pp'] = ((treatment_df['post_skip_rate'] - treatment_df['baseline_skip_rate']) * 100)\n",
    "skip_summary = treatment_df.groupby('segment')['skip_change_pp'].agg(['mean', 'std']).round(1)\n",
    "print(\"\\nTreatment Group - Skip Rate Change (pp) by Segment:\")\n",
    "print(skip_summary)\n",
    "\n",
    "# Control group\n",
    "control_skip_change = ((control_df['post_skip_rate'] - control_df['baseline_skip_rate']) * 100).mean()\n",
    "print(f\"\\nControl Group - Skip Rate Change: {control_skip_change:.2f}pp (expected: ~0pp)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62818431",
   "metadata": {},
   "source": [
    "### Guardrail Violations Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d84360",
   "metadata": {},
   "source": [
    "\n",
    "- Threshold: Session length should not decrease by >5%\n",
    "- Threshold: Skip rate should not increase by >10pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "af16eea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narrow Comfort Zone: Skip rate increased by 11.6pp (EXCEEDS THRESHOLD)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "violations = []\n",
    "for segment in treatment_df['segment'].unique():\n",
    "    seg_data = treatment_df[treatment_df['segment'] == segment]\n",
    "    \n",
    "    avg_session = seg_data['session_lift_pct'].mean()\n",
    "    avg_skip = seg_data['skip_change_pp'].mean()\n",
    "    \n",
    "    if avg_session < -5:\n",
    "        violations.append(f\"{segment}: Session length decreased by {avg_session:.1f}%\")\n",
    "    \n",
    "    if avg_skip > 10:\n",
    "        violations.append(f\"{segment}: Skip rate increased by {avg_skip:.1f}pp (EXCEEDS THRESHOLD)\")\n",
    "\n",
    "if violations:\n",
    "    for v in violations:\n",
    "        print(v)\n",
    "else:\n",
    "    print(\"All guardrails within acceptable ranges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ba915",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c46af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"playlist_complete_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee6bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
